# ToTheMoon

# Plan...
1. Fetch data points using python script and Bybit.com api
2. Output correctly formatted data to data.m (we want sets of 40 klines (each kline has 6 attributes), the y label will be the last klines close / open ratio?)
3. Use octave NN backprop to learn params (where it'll take first 39 klines and last kline's open price to determine y = )

- we want y to be a classification problem between buy and sell.
- so some decimal between 0 and 1
we will label each dataset's y as some float between 0 and 1
to determine y for each set. we will look at close / open ratio in relationship to max close / open ratio of entire set??

does nn need to know the scale of the buy? or just needs to differentiate between buy and sell binarily?
i think for now we can just do binary
label each set as buy or sell.

architecture 240 300 300 1

lets do 80 20 split training / test
nn

# First training set with 50 epochs and 241 * 40 * 3 nodes was getting .27 accuracy on train and .29 on test
* plan is to use normalization and mess around with lambda, also give more epochs?
* get rid of some of the bad data...
* according to ng notes lambda should be chosen using 0, 0.001, 0.003, 0.01, 0.03, 0.1 ... 10 using cross validation set
  1. Train Theta using small epochs and for all values of lambda [0, 0.001, 0.003, 0.01]...
  2. using cross validation set choose lambda with lowest cost.

# TODOS
* re-organize util functions using oop? nah.
* use octave scripts to learn params
